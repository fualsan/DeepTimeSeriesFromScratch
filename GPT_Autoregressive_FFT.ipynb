{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb1107d-9a96-4d47-ab3e-0582fd89827d",
   "metadata": {},
   "source": [
    "# Time Series Forecasting with Autoregressive GPT with FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2358b-d53a-43e3-9d26-d38b8f7649d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'USING DEVICE: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb0bc4-3118-48c0-8f61-2b53d10bbc32",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288dc719-d4cc-4494-8ffd-19cb73db213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_fft = ['nat_demand'] # TODO: add features here that require FFT\n",
    "\n",
    "hyperparameters = {\n",
    "    'window_size': 100, # also 'context_size'\n",
    "    'features_with_fft': features_with_fft,\n",
    "    'input_features_size': 16 + len(features_with_fft),\n",
    "    'date_input_features_size': 3, # (MONTH, DAY, HOUR)\n",
    "    'date_features_dim': 64,\n",
    "    'hidden_features_size': 256-64, # will be concat inside model\n",
    "    'output_features_size': 16 + len(features_with_fft),\n",
    "    'num_heads': 4,\n",
    "    'ff_dim': 256*4, # usually 4 times the hidden feature size\n",
    "    'num_decoder_layers': 12,\n",
    "    'emb_dropout_prob': 0.1,\n",
    "    'attn_dropout_prob': 0.1,\n",
    "    'ff_dropout_prob': 0.1,\n",
    "    'attn_use_bias': False,\n",
    "    'ff_use_bias': False,\n",
    "    'output_features_bias': False,\n",
    "    'batch_size': 128,\n",
    "    'split_ratio': 0.8, # 80% training, 20% testing\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 60,\n",
    "    'use_amp': True, # USE MIXED PRECISION\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743a1f6-d57a-490e-9ac0-bb41ff95a352",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db563c03-1ee8-417d-926e-ddd837b766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airline Passgeners\n",
    "#df_full = pd.read_csv('data/airline_passengers/airline-passengers.csv')\n",
    "\n",
    "# Panama Electricity Load Forecasting\n",
    "df_full = pd.read_csv('data/panama_electricity_load_forecasting/train.csv')\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282fb84-75ad-4629-b9c9-5c0e01cae8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airline Passgeners\n",
    "#df_full['Month'] = pd.to_datetime(df_full['Month'])\n",
    "\n",
    "# Panama Electricity Load Forecasting\n",
    "df_full['datetime'] = pd.to_datetime(df_full['datetime'], dayfirst=True)\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58545c8-31ee-483e-b1fc-028efcb0873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Airline Passgeners\n",
    "#df_full.set_index('Month', inplace=True)\n",
    "\n",
    "# Panama Electricity Load Forecasting\n",
    "df_full.set_index('datetime', inplace=True)\n",
    "\n",
    "df_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23042d10-d9ba-4255-81a8-b0e2aafba703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airline Passgeners\n",
    "#df_full.plot()\n",
    "\n",
    "# Panama Electricity Load Forecasting\n",
    "df_full.loc['2019-01-03 05:00:00':'2019-01-12 05:00:00', 'nat_demand'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c8752-4487-4375-87ad-e9311f3cde86",
   "metadata": {},
   "source": [
    "# Standart Scaler\n",
    "* Exercise: Try without scaler, see if learning works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6ad4c-27af-4d30-b19d-c07308ac6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "\n",
    "# Airline Passgeners\n",
    "#df_full['Passengers'] = scaler.fit_transform(df_full['Passengers'].values.reshape(-1, 1))\n",
    "\n",
    "# Panama Electricity Load Forecasting\n",
    "df_full[df_full.columns] = feature_scaler.fit_transform(df_full[df_full.columns])\n",
    "\n",
    "# Airline Passgeners\n",
    "#df_full.plot()\n",
    "\n",
    "# Panama Electricity Load Forecasting\n",
    "df_full.loc['2019-01-03 05:00:00':'2019-01-12 05:00:00', 'nat_demand'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968abec2-9cbd-47c0-b913-c87e175b9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = df_full.index[-1]\n",
    "tstamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7b0b8-ee9d-4c5b-9558-872feca3f4dc",
   "metadata": {},
   "source": [
    "# Time series data shape: \n",
    "Unbatched: $(S, F)$\n",
    "\n",
    "* $S:$ Sequence Length\n",
    "* $F:$ Number of Features\n",
    "\n",
    "Batched: $(B, S, F)$\n",
    "* $B:$ Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f8373-2896-4644-bbab-5f5a912892d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66106ad6-4eb2-45ea-9534-769a64bc23c1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90408c65-d0cd-43ff-bb19-3a7372afbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import GPTTimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21028a64-d051-4443-8e6c-7c61953b0ca5",
   "metadata": {},
   "source": [
    "## Transformer Model\n",
    "### Initialized Model with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62a5b6-6a2a-4bf6-82ac-b7564ff34352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTTimeSeries(\n",
    "    input_features_size=hyperparameters['input_features_size'],\n",
    "    date_input_features_size=hyperparameters['date_input_features_size'],\n",
    "    date_features_dim=hyperparameters['date_features_dim'],\n",
    "    features_dim=hyperparameters['hidden_features_size'],\n",
    "    output_features_size=hyperparameters['output_features_size'],\n",
    "    num_heads=hyperparameters['num_heads'],\n",
    "    ff_dim=hyperparameters['ff_dim'],\n",
    "    num_decoder_layers=hyperparameters['num_decoder_layers'],\n",
    "    emb_dropout_prob=hyperparameters['emb_dropout_prob'],\n",
    "    attn_dropout_prob=hyperparameters['attn_dropout_prob'],\n",
    "    ff_dropout_prob=hyperparameters['ff_dropout_prob'],\n",
    "    attn_use_bias=hyperparameters['attn_use_bias'],\n",
    "    ff_use_bias=hyperparameters['ff_use_bias'],\n",
    "    output_features_bias=hyperparameters['output_features_bias'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde0d98-32af-40f7-aa7c-6fb9e1e9d15e",
   "metadata": {},
   "source": [
    "### Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aea2e7-7cc0-41a4-98d9-abbfe855f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_parameters(model):\n",
    "    print(f'{sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ac969-c12d-4271-9836-ae00d34c78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of parameters:')\n",
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2e080-45e8-4a64-acc1-373d17ad0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"1\" is the batch, single sample to speed it up\n",
    "dummy_data = torch.randn(1, hyperparameters['window_size'], hyperparameters['input_features_size'])\n",
    "dummy_date = torch.randn(1, hyperparameters['window_size'], hyperparameters['date_input_features_size'])\n",
    "\n",
    "o = model(dummy_data, dummy_date)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788b143-e04e-4a5e-9634-fe3b7bd9d3c4",
   "metadata": {},
   "source": [
    "# FFT as Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a15b9d-6eed-4438-b737-7fd520cb8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency_components(data, sampling_rate):\n",
    "    fft_result = np.fft.fft(data)\n",
    "    fft_freqs = np.fft.fftfreq(len(data), 1/sampling_rate)\n",
    "    return fft_freqs, fft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38210d-ee43-4295-8a98-149a275521e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(fft_result):\n",
    "    # IFFT is complex!\n",
    "    return np.fft.ifft(fft_results).real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263df7d1-68ae-4be8-a832-69d1dd47e291",
   "metadata": {},
   "source": [
    "# BandPass Filter\n",
    "\n",
    "A bandpass filter allows signals within a specific frequency range to pass through while cutting off the frequencies outside that range\n",
    "* Frequency Range: $[\\text{low\\_cutoff}, \\text{high\\_cutoff}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c8d28-22b2-4bd8-827e-8cc0f89fb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(fft_result, low_cutoff=10.0, high_cutoff=1000.0):\n",
    "    filtered_fft_results = np.zeros_like(fft_result)\n",
    "    \n",
    "    # pass only frequencies between low and high cutoff frequencies\n",
    "    for i in range(len(fft_result)):\n",
    "        if low_cutoff <= np.abs(fft_result[i]) <= high_cutoff:\n",
    "            filtered_fft_results[i] = fft_result[i]\n",
    "\n",
    "    return filtered_fft_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ad80e-fa02-4b75-97e4-c1e4f3c61c51",
   "metadata": {},
   "source": [
    "# Frequency Features\n",
    "### Calculate sampling rate from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b96f3d-2490-4a81-bc50-98911e7d96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_delta_time = df_full.index.diff(periods=1).dropna().total_seconds().to_numpy().mean()\n",
    "SAMPLING_RATE = 1 / avg_delta_time\n",
    "\n",
    "# NOTE: since dataset is hourly sampled, sampling rate is really low\n",
    "# most of the time, this is not the case!\n",
    "print(f'Sampling Rate: {SAMPLING_RATE} Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad892e73-ae2a-40d1-ad8f-32fdefa5911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_featues(data_column, sampling_rate):\n",
    "    fft_freqs, fft_results = calculate_frequency_components(data_column, sampling_rate)\n",
    "    filtered_fft_results = bandpass_filter(fft_results)\n",
    "    magnitude = np.abs(filtered_fft_results)\n",
    "    return magnitude\n",
    "\n",
    "# helper function for setting \"sampling rate\"\n",
    "# ignore second of input tuple (values, datetime)\n",
    "add_frequency_features = lambda data_column: frequency_featues(data_column, SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42fd9c-ba8c-4453-9f2c-28298878cc78",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad354d-f77e-49a5-b3ec-5da382d9cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, window_size, features_with_fft):\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.features_with_fft = features_with_fft\n",
    "    \n",
    "    def __len__(self):\n",
    "        number_of_samples = self.df.shape[0]\n",
    "        # make sure that last window fits\n",
    "        return number_of_samples - self.window_size\n",
    "\n",
    "    def __getitem__(self, start_idx):\n",
    "\n",
    "        # get a NumPy array of size: (hyperparameters['window_size'], NUM_FEATURES)\n",
    "        df_window_original = self.df.iloc[start_idx:start_idx+self.window_size]\n",
    "\n",
    "        df_window = df_window_original.copy()\n",
    "        \n",
    "        # FFT features\n",
    "        for _feature_name in self.features_with_fft:\n",
    "            fft_frequencies = add_frequency_features(df_window[f'{_feature_name}'].values)\n",
    "            df_window.loc[:, f'{_feature_name}_fft'] = fft_frequencies\n",
    "        \n",
    "        sample_window = df_window.values\n",
    "        # input (lag) timestamps\n",
    "        sample_timestamp_lags = df_window[:-1].index\n",
    "            \n",
    "        # divide window into lags and forecast (shifted by 1)\n",
    "        # first window_size-1 steps\n",
    "        lags = sample_window[:-1, :]\n",
    "        # last window_size-1 steps\n",
    "        forecast = sample_window[1:, :]\n",
    "\n",
    "        # convert to tensor\n",
    "        lags = torch.tensor(lags, dtype=torch.float32)\n",
    "        forecast = torch.tensor(forecast, dtype=torch.float32)\n",
    "        \n",
    "        # (lags, date_input_features_size)\n",
    "        date = torch.tensor([sample_timestamp_lags.month, sample_timestamp_lags.day, sample_timestamp_lags.hour], dtype=torch.float32).permute(1, 0)\n",
    "        \n",
    "        return lags, forecast, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dcf40-189e-4f2b-bc04-9a6a73cd1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = TimeSeriesDataset(\n",
    "    df_full,\n",
    "    hyperparameters['window_size'],\n",
    "    features_with_fft=hyperparameters['features_with_fft'] # TODO: add features here that require FFT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ccea2-bc70-4e55-9ab1-9f71c79a1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lags, _forecast, _date = dataset_full[0]\n",
    "_lags.shape, _forecast.shape, _date.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65347aee-d469-4ebf-8499-767dacb6a102",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccdaaa6-c1d5-42ad-a66f-6c3539a4ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(hyperparameters['split_ratio'] * len(dataset_full))\n",
    "test_size = len(dataset_full) - train_size\n",
    "\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098f3c5-0cd2-4d64-8ff3-de5b85d28d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_full.iloc[:train_size, :]\n",
    "df_test = df_full.iloc[-test_size:, :]\n",
    "\n",
    "# Airline Passgeners\n",
    "#plt.plot(df_train.index, df_train['Passengers'], c='blue', label='training')\n",
    "#plt.plot(df_test.index, df_test['Passengers'], c='red', label='test')\n",
    "\n",
    "# Panama Electricity Load Forecasting\n",
    "plt.plot(df_train.index, df_train['nat_demand'], c='blue', label='training')\n",
    "plt.plot(df_test.index, df_test['nat_demand'], c='red', label='test')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d20db-2358-494b-927c-196a3c407bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TimeSeriesDataset(\n",
    "    df_train,\n",
    "    hyperparameters['window_size'],\n",
    "    features_with_fft=hyperparameters['features_with_fft'] # TODO: add features here that require FFT\n",
    ")\n",
    "\n",
    "dataset_test = TimeSeriesDataset(\n",
    "    df_test,\n",
    "    hyperparameters['window_size'],\n",
    "    features_with_fft=hyperparameters['features_with_fft'] # TODO: add features here that require FFT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9516e1-f1ee-4db5-b6e3-3a9d76f0b20d",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acba036-7c98-4786-9c00-5af6325f8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_full = DataLoader(\n",
    "    dataset_full,\n",
    "    batch_size=hyperparameters['batch_size'],\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=hyperparameters['batch_size'],\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=hyperparameters['batch_size'],\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f'Number of batches (total): {len(dataloader_full)}')\n",
    "print(f'Number of batches (train): {len(dataloader_train)}')\n",
    "print(f'Number of batches (test): {len(dataloader_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4ab76-bc6a-4827-9686-e5f10b66987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lags_batch, _forecast_batch, _date_batch = next(iter(dataloader_full))\n",
    "# (hyperparameters['batch_size'], hyperparameters['lags'], NUM_FEATURES), # (hyperparameters['batch_size'], hyperparameters['forecast'], NUM_FEATURES)\n",
    "_lags_batch.shape, _forecast_batch.shape, _date_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092102e2-5185-43f7-947b-81abf7bdf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader_full)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffc14438-3d06-4c12-8756-e2f7eaf95b28",
   "metadata": {},
   "source": [
    "for idx, (s) in enumerate(dataloader_full):\n",
    "    print(idx)\n",
    "    print(s[0].shape, s[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a30eb6-4ac5-4dfa-b7d7-873168eb2339",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15bf614-596e-4c9b-abfe-91d933c05d76",
   "metadata": {},
   "source": [
    "### Training Functions\n",
    "* with AMP support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003c1c4-c9ae-4f24-8e72-6f8ea31285dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iter(model, dataloader, optimizer, criterion, scaler, use_amp, device):\n",
    "    model.train()\n",
    "\n",
    "    avg_loss = []\n",
    "    \n",
    "    for (lags, forecast, date) in dataloader:\n",
    "\n",
    "        lags = lags.to(device)\n",
    "        forecast = forecast.to(device)\n",
    "        date = date.to(device)\n",
    "        \n",
    "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "            # AMP forward pass\n",
    "            forecast_pred = model(lags, date)\n",
    "            loss = criterion(forecast_pred, forecast)\n",
    "        \n",
    "        scaler.scale(loss).backward()  #loss.backward()\n",
    "        scaler.step(optimizer)         #optimizer.step()\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        avg_loss.append(loss.item())\n",
    "\n",
    "    return sum(avg_loss) / len(avg_loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_iter(model, dataloader, criterion, use_amp, device):\n",
    "    model.eval()\n",
    "\n",
    "    avg_loss = []\n",
    "    predictions = []\n",
    "    \n",
    "    for (lags, forecast, date) in dataloader:\n",
    "        \n",
    "        lags = lags.to(device)\n",
    "        forecast = forecast.to(device)\n",
    "        date = date.to(device)\n",
    "                \n",
    "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "            # AMP forward pass\n",
    "            forecast_pred = model(lags, date)\n",
    "            loss = criterion(forecast_pred, forecast)\n",
    "        \n",
    "        avg_loss.append(loss.item())\n",
    "        predictions.append(forecast_pred)\n",
    "\n",
    "    return sum(avg_loss) / len(avg_loss), predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3e836-bd62-4e58-840a-18a5db7dec44",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d953510-def3-4d02-8847-40c28e59214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hyperparameters['learning_rate']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min', \n",
    "    factor=0.1, \n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=hyperparameters['use_amp'])\n",
    "\n",
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f98b9-3175-4d0c-855a-f054321d2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "for epoch in range(1, hyperparameters['num_epochs']+1):\n",
    "        \n",
    "    avg_train_loss = train_iter(\n",
    "        model=model, \n",
    "        dataloader=dataloader_train, \n",
    "        optimizer=optimizer, \n",
    "        criterion=mse_loss, \n",
    "        scaler=scaler, \n",
    "        use_amp=hyperparameters['use_amp'], \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    avg_test_loss, _ = eval_iter(\n",
    "        model=model, \n",
    "        dataloader=dataloader_test, \n",
    "        criterion=mse_loss, \n",
    "        use_amp=hyperparameters['use_amp'],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # auto decrease LR when not improving\n",
    "    scheduler.step(avg_test_loss)\n",
    "    \n",
    "    \"\"\"\n",
    "    # MANUAL LR SCHEDULING\n",
    "    if epoch == 30:\n",
    "        for pg in optimizer.param_groups:\n",
    "            pg['lr'] *= 0.1\n",
    "\n",
    "    if epoch == 60:\n",
    "        for pg in optimizer.param_groups:\n",
    "            pg['lr'] *= 0.1\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Epoch: {epoch:<3}| Training loss: {avg_train_loss:.4f}, Testing Loss: {avg_test_loss:.4f}, LR: {scheduler.get_last_lr()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d22bf5-4588-4c5b-914b-237833db8293",
   "metadata": {},
   "source": [
    "# Testing\n",
    "* NOTE: we prefer to use single windows step during prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d19abb-3e77-4c33-9f37-c65c457ab413",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_iter_single_step(model, dataloader, criterion, use_amp, device):\n",
    "    model.eval()\n",
    "\n",
    "    avg_loss = []\n",
    "    predictions = []\n",
    "    \n",
    "    # single step\n",
    "    for start_idx in tqdm(range(0, len(df_test)-hyperparameters['window_size'])):\n",
    "\n",
    "        # single step window sliding\n",
    "        df_window_original = df_test.iloc[start_idx:start_idx+hyperparameters['window_size'], :]\n",
    "\n",
    "        # add FFT features\n",
    "        df_window = df_window_original.copy()\n",
    "        \n",
    "        for _feature_name in hyperparameters['features_with_fft']:\n",
    "            fft_frequencies = add_frequency_features(df_window[f'{_feature_name}'].values)\n",
    "            df_window.loc[:, f'{_feature_name}_fft'] = fft_frequencies\n",
    "        \n",
    "        sample_window = df_window.values\n",
    "        # input (lag) timestamps\n",
    "        sample_timestamp_lags = df_window[:-1].index\n",
    "\n",
    "        # covnert to tensor\n",
    "        lags = torch.tensor(sample_window[:-1], dtype=torch.float32, device=device)\n",
    "        forecast = torch.tensor(sample_window[1:], dtype=torch.float32, device=device)\n",
    "        # (lags, date_input_features_size)\n",
    "        date = torch.tensor([sample_timestamp_lags.month, sample_timestamp_lags.day, sample_timestamp_lags.hour], dtype=torch.float32, device=device).permute(1, 0)\n",
    "        \n",
    "        # artificially add batch dimension\n",
    "        # (we are not using the dataloader here!)\n",
    "        lags = lags.unsqueeze(0)\n",
    "        forecast = forecast.unsqueeze(0)\n",
    "        date = date.unsqueeze(0)\n",
    "\n",
    "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "            forecast_pred = model(lags, date)\n",
    "            loss = criterion(forecast_pred, forecast)\n",
    "            \n",
    "        avg_loss.append(loss.item())\n",
    "        # (batch, forecast, output_features_size)-> (1, window_size-1, output_features_size)\n",
    "        # TAKE THE LAST PREDICTION STEP AS FORECAST!\n",
    "        predictions.append(forecast_pred[0][-1].cpu().numpy())\n",
    "\n",
    "    return sum(avg_loss) / len(avg_loss), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab7f2f-c398-4154-97e2-efd8b9d88cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred_sliding = eval_iter_single_step(\n",
    "    model=model, \n",
    "    dataloader=dataloader_test, \n",
    "    criterion=mse_loss, \n",
    "    use_amp=hyperparameters['use_amp'],\n",
    "    device=device\n",
    ")\n",
    "\n",
    "len(pred_sliding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc489fe-1b8f-481d-a0f0-e2b3c801c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ca0b4-2951-452a-b0da-2dd19717944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_results_dict = {}\n",
    "\n",
    "pred_sliding_array = np.array(pred_sliding)\n",
    "\n",
    "for feature_id, feature_key in enumerate(df_full.columns):\n",
    "    sliding_results_dict[feature_key] = pred_sliding_array[:, feature_id]\n",
    "        \n",
    "df_sliding = pd.DataFrame(data=sliding_results_dict, index=df_test.index[:-hyperparameters['window_size']])\n",
    "\n",
    "df_sliding.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1934a-8d85-441f-bc84-0dade96b7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = 'nat_demand'\n",
    "\n",
    "df_train_plot = df_train[:-hyperparameters['window_size']].copy()\n",
    "df_test_plot = df_test[:-hyperparameters['window_size']].copy()\n",
    "\n",
    "plt.plot(df_train_plot.index, df_train_plot[selected_feature], c='blue', label='training')\n",
    "plt.plot(df_test_plot.index, df_test_plot[selected_feature], c='red', label='test')\n",
    "plt.plot(df_sliding.index, df_sliding[selected_feature] , c='green', label='prediction')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18fd2f-2bc0-431b-8cdc-3f4b711e0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df_test.loc['2019-01-03 05:00:00':'2019-01-12 05:00:00', 'nat_demand'].plot(label='actual')\n",
    "df_sliding.loc['2019-01-03 05:00:00':'2019-01-12 05:00:00', 'nat_demand'].plot(label='prediction')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0d119-19bc-4098-99dc-18a5b8cc581f",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8c44e-2861-49e1-aca8-cd2593bc8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./saved_models', exist_ok=True)\n",
    "\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'hyperparameters': hyperparameters,\n",
    "}\n",
    "\n",
    "if hyperparameters['use_amp']:\n",
    "    checkpoint['scaler_state_dict'] = scaler.state_dict()\n",
    "\n",
    "torch.save(\n",
    "    checkpoint,\n",
    "    './saved_models/GPTTimeSeries_Autoregressive_FFT.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf35c6-0043-4533-ac32-ea186c2cefbb",
   "metadata": {},
   "source": [
    "# Generative Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fe843-6e44-4e06-8f6f-3ceec8e4f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generative_forecast(model, data, timestamps, num_steps, lag_window_size, use_amp, device):\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    time_indexes = []\n",
    "    \n",
    "    # covnert to tensor\n",
    "    # data.shape: (lags, features)\n",
    "    lags = torch.tensor(data[-lag_window_size:, :], dtype=torch.float32, device=device)\n",
    "    \n",
    "    # artificially add batch dimension\n",
    "    # (we are not using the dataloader here!)\n",
    "    # data.shape: (1, lags, features)\n",
    "    lags = lags.unsqueeze(0)\n",
    "\n",
    "    # Datetime indexes \n",
    "    #timestamps = df_full.index \n",
    "    # Delta time: calculate the time difference between two samples \n",
    "    delta_time = timestamps[1] - timestamps[0]\n",
    "    # Get last timestamp\n",
    "    current_timestamp = timestamps[-1]\n",
    "\n",
    "    def generate_date_tensor(_timestamp, _lags, _device):\n",
    "        _timestamp = _timestamp[-lag_window_size:]\n",
    "        return torch.tensor([_timestamp.month, _timestamp.day, _timestamp.hour], dtype=torch.float32, device=_device).permute(1, 0)\n",
    "    \n",
    "    # single step\n",
    "    for idx in tqdm(range(num_steps)):\n",
    "\n",
    "        # get the last lag steps\n",
    "        lags = lags[:, -lag_window_size:, :]\n",
    "        #print(lags)\n",
    "\n",
    "        # date\n",
    "        date = generate_date_tensor(timestamps, lag_window_size, device).unsqueeze(0)\n",
    "\n",
    "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "            forecast_pred = model(lags, date)\n",
    "        \n",
    "        # (batch, forecast, output_features_size)-> (1, window_size-1, output_features_size)\n",
    "        # TAKE THE LAST PREDICTION STEP AS FORECAST!\n",
    "        predictions.append(forecast_pred[0][-1].cpu().numpy())\n",
    "\n",
    "        # update current timestamp\n",
    "        current_timestamp = current_timestamp + delta_time\n",
    "        time_indexes.append(current_timestamp)\n",
    "        \n",
    "        # append last forecast to the end\n",
    "        # TAKE THE LAST PREDICTION STEP AS FORECAST!\n",
    "        lags = torch.cat((lags, forecast_pred[:, -1:, :].detach()), dim=1)\n",
    "        \n",
    "        # next timestamp\n",
    "        timestamps = timestamps + delta_time\n",
    "\n",
    "    return predictions, time_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514d5aa-9123-4614-9818-d61524bb2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be min of original model\n",
    "REQUEST_WINDOW_SIZE = 200 * 2 # * 2 is added for convenience\n",
    "# temp dataframe for generative prediction input\n",
    "df_temp_original = df_full[-REQUEST_WINDOW_SIZE:]\n",
    "\n",
    "# Add FFT features\n",
    "df_temp = df_temp_original.copy()\n",
    "\n",
    "for _feature_name in hyperparameters['features_with_fft']:\n",
    "    fft_frequencies = add_frequency_features(df_temp[f'{_feature_name}'].values)\n",
    "    df_temp.loc[:, f'{_feature_name}_fft'] = fft_frequencies\n",
    "        \n",
    "\n",
    "pred_generative, time_indexes_generative = generative_forecast(\n",
    "    model=model, \n",
    "    data=df_temp.values,\n",
    "    timestamps=df_temp.index,\n",
    "    num_steps=300, \n",
    "    lag_window_size=hyperparameters['window_size'], \n",
    "    use_amp=hyperparameters['use_amp'], \n",
    "    device=device\n",
    ")\n",
    "\n",
    "pred_generative_array = np.array(pred_generative)\n",
    "\n",
    "generative_results_dict = {}\n",
    "\n",
    "# loop ove features\n",
    "for feature_id, feature_key in enumerate(df_temp.columns):\n",
    "    generative_results_dict[feature_key] = pred_generative_array[:, feature_id]\n",
    "        \n",
    "df_generative = pd.DataFrame(data=generative_results_dict, index=time_indexes_generative)\n",
    "\n",
    "# REVERSE THE PREPROCESSING FOR ORIGINAL RANGE\n",
    "columns_without_fft = [c for c in df_generative.columns if not 'fft' in c]\n",
    "df_generative[columns_without_fft] = feature_scaler.inverse_transform(df_generative[columns_without_fft])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb024d8d-cd2f-4272-904b-66847a442879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generative[selected_feature].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacec48f-4336-4675-ad3d-e8fbf2bcb79d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
